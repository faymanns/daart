# currently supported: temporal-mlp, lstm, gru, tcn, dtcn
model_type: dtcn

# hidden layers for both classifier and predictor networks
n_hid_layers: 2

# hidden units per layer
n_hid_units: 32

# half-width of temporal convolution window for temporal-mlp, tcns
n_lags: 4

# layer nonlinearity
activation: lrelu

# hyperparam on classifying weak labels
lambda_weak: [0, 0.1, 0.5, 1]

# hyperparam on classifying strong labels
lambda_strong: 1

# hyperparam on one-step-ahead prediciton
lambda_pred: [0, 0.1, 0.5, 1]

# name of experiment for test-tube organizing
tt_experiment_name: test

# control initialization of model
rng_seed_model: 0

# bidirectionality of RNNs (LSTM, GRU)
bidirectional: true

# dropout for individual channels of dilated TCN models (soon to be for others)
dropout: 0.1
